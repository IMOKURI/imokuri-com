---
title: vLLM Sleep Mode
slug: vllm-sleep-mode
date: 2025-07-09
updated: 2025-10-20
tags:
    - LLM
    - Deep Learning
description: "vLLMã®sleep modeã«ã¤ã„ã¦"
---

## Contents

## Overview

vLLM ã¯ã€1ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã§1ã¤ã®ãƒ¢ãƒ‡ãƒ«ã‚’å‹•ã‹ã—ã¾ã™ã€‚
ãã®ãƒ¢ãƒ‡ãƒ«ã®ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’æœ€å¤§åŒ–ã™ã‚‹ãŸã‚ã€GPUãƒ¡ãƒ¢ãƒªã®æ®†ã©ã®é ˜åŸŸã‚’KV Cacheã¨ã—ã¦åˆ©ç”¨ã—ã¾ã™ã€‚

ä¸€æ–¹ã§ã€vLLMã®èµ·å‹•ã«ã¯ã€torch compileã‚„é‡å­åŒ–ã€ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ã®ãŸã‚ã«ã€æ•°åˆ†ç¨‹åº¦ã‚’è¦ã™ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚
ãã“ã§ã€è¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«ã‚’ã€Œã•ã£ã¨ã€åˆ‡ã‚Šæ›¿ãˆã‚‹ãŸã‚ã«ã€vLLMã¯ã€Œsleep modeã€ã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚

vLLMã‚’èµ·å‹•ã™ã‚‹éš›ã«ã€ ç’°å¢ƒå¤‰æ•° `VLLM_SERVER_DEV_MODE=1` ã¨ ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•° `--enable-sleep-mode` ã‚’ã¤ã‘ã¦èµ·å‹•ã—ã¾ã™ã€‚

> [!note]
> ã“ã®ç’°å¢ƒå¤‰æ•°ã«ã‚ˆã£ã¦åˆ©ç”¨å¯èƒ½ã«ãªã‚‹ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã¯ã‚¨ãƒ³ãƒ‰ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã¯å…¬é–‹ã—ãªã„ã“ã¨ãŒæ¨å¥¨ã•ã‚Œã¦ã„ã¾ã™ã€‚

## Sleep

ã“ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ã‚¹ãƒªãƒ¼ãƒ—ãƒ¢ãƒ¼ãƒ‰ã«ã—ãŸã„ã¨ãã¯ã€ `/sleep` ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã«ã€ã‚¹ãƒªãƒ¼ãƒ—ã®ãƒ¬ãƒ™ãƒ«ã‚’ã‚ã‚ã›ã¦ã€ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’æŠ•ã’ã¾ã™ã€‚

```bash
curl -X POST localhost:8000/sleep -d '{"level":1}'
```

ã‚¹ãƒªãƒ¼ãƒ—ãƒ¢ãƒ¼ãƒ‰ã®ãƒ¬ãƒ™ãƒ«ã¯ã€ä»¥ä¸‹ã®ã‚ˆã†ã«è¨­å®šã§ãã¾ã™ã€‚

- `1`: KV Cacheã‚’GPUãƒ¡ãƒ¢ãƒªã‹ã‚‰å‰Šé™¤ã—ã€ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã¯CPUãƒ¡ãƒ¢ãƒªã«ã‚ªãƒ•ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚
- `2`: KV Cacheã‚’GPUãƒ¡ãƒ¢ãƒªã‹ã‚‰å‰Šé™¤ã—ã€ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚‚å‰Šé™¤ã—ã¾ã™ã€‚

å®Ÿéš›ã«ã€sleepãƒ¢ãƒ¼ãƒ‰ã«å…¥ã‚‹ã¨ä»¥ä¸‹ã®ã‚ˆã†ãªãƒ­ã‚°ãŒå‡ºåŠ›ã•ã‚Œã¾ã™(ãƒ¬ãƒ™ãƒ«1ã®å ´åˆ)ã€‚
ä¸€åº¦ sleepãƒ¢ãƒ¼ãƒ‰ã«å…¥ã£ã¦ã„ã‚‹ã¨ã€äºŒåº¦ç›®ã‹ã‚‰ã¯ã€éå¸¸ã«é«˜é€Ÿã« sleepãƒ¢ãƒ¼ãƒ‰ã«å…¥ã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã™ã€‚

```log /It took [0-9\.]+ seconds/
# 1å›ç›®
(EngineCore_DP0 pid=87) INFO 10-19 19:38:37 [block_pool.py:378] Successfully reset prefix cache
(Worker pid=125) INFO 10-19 19:39:19 [cumem.py:228] CuMemAllocator: sleep freed 83.04 GiB memory in total, of which 75.16 GiB is backed up in CPU and the rest 7.88 GiB is discarded directly.
(Worker pid=125) INFO 10-19 19:39:20 [gpu_worker.py:117] Sleep mode freed 83.28 GiB memory, 5.82 GiB memory is still in use.
(EngineCore_DP0 pid=87) INFO 10-19 19:39:20 [executor_base.py:189] It took 43.489556 seconds to fall asleep.

# 2å›ç›®
(APIServer pid=1) INFO 10-19 19:48:31 [api_server.py:1024] check whether the engine is sleeping
(EngineCore_DP0 pid=87) INFO 10-19 19:48:59 [block_pool.py:378] Successfully reset prefix cache
(Worker pid=125) INFO 10-19 19:49:03 [cumem.py:228] CuMemAllocator: sleep freed 83.04 GiB memory in total, of which 75.16 GiB is backed up in CPU and the rest 7.88 GiB is discarded directly.
(Worker pid=125) INFO 10-19 19:49:06 [gpu_worker.py:117] Sleep mode freed 83.04 GiB memory, 5.82 GiB memory is still in use.
(EngineCore_DP0 pid=87) INFO 10-19 19:49:06 [executor_base.py:189] It took 6.523925 seconds to fall asleep.
```

sleepãƒ¢ãƒ¼ãƒ‰å‰å¾Œã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®å¤‰åŒ–ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚sleepãƒ¢ãƒ¼ãƒ‰ä¸­ã§ã‚‚ã€GPUãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒ0ã«ã¯ãªã‚‰ãªã„ã“ã¨ã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚

```log /[0-9]+MiB/
# GPUãƒ¡ãƒ¢ãƒª Before Sleep
|    0   N/A  N/A         1979459      C   VLLM::Worker                          87496MiB |

# GPUãƒ¡ãƒ¢ãƒª After Sleep Level 1
|    0   N/A  N/A         1979459      C   VLLM::Worker                           2066MiB |

# CPUãƒ¡ãƒ¢ãƒª Before Sleep
               total        used        free      shared  buff/cache   available
Mem:             125          26           2           0          97          99

# CPUãƒ¡ãƒ¢ãƒª After Sleep Level 1
               total        used        free      shared  buff/cache   available
Mem:             125         102          11          77          90          22
```


sleepãƒ¢ãƒ¼ãƒ‰ä¸­ã«ã€ãƒãƒ£ãƒƒãƒˆãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’æŠ•ã’ã¦ã—ã¾ã†ã¨ã€ä»¥ä¸‹ã®ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã€vLLMãŒåœæ­¢ã—ã¦ã—ã¾ã„ã¾ã™ã€‚ã€‚

```json
{
  "error": {
    "message": "EngineCore encountered an issue. See stack trace (above) for the root cause.",
    "type": "Internal Server Error",
    "param": null,
    "code": 500
  }
}
```


## Wake Up

ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã«ã—ãŸã„ã¨ãã¯ã€ `/wake_up` ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’æŠ•ã’ã¾ã™ã€‚

```bash
curl -X POST localhost:8000/wake_up
```

å®Ÿéš›ã«ã€wake upã™ã‚‹ã¨ä»¥ä¸‹ã®ã‚ˆã†ãªãƒ­ã‚°ãŒå‡ºåŠ›ã•ã‚Œã¾ã™ã€‚ã¨ã¦ã‚‚é«˜é€Ÿã«å¾©å¸°ã™ã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã™ã€‚

```log /It took [0-9\.]+ seconds/
(APIServer pid=1) INFO 10-19 19:45:09 [api_server.py:1024] check whether the engine is sleeping
(APIServer pid=1) INFO 10-19 19:45:40 [api_server.py:1016] wake up the engine with tags: None
(EngineCore_DP0 pid=87) INFO 10-19 19:45:42 [executor_base.py:205] It took 1.544127 seconds to wake up tags {'kv_cache', 'weights'}.
```


## References

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Pro-tip for vLLM power-users: free â‰ˆ 90 % of your GPU VRAM in secondsâ€”no restarts requiredğŸš€<br><br>ğŸš© Why youâ€™ll want this<br>â€¢ Hot-swap new checkpoints on the same card<br>â€¢ Rotate multiple LLMs on one GPU (batch jobs, micro-services, A/B tests)<br>â€¢ Stage-based pipelines that callâ€¦ <a href="https://t.co/WAzdiZWL6u">pic.twitter.com/WAzdiZWL6u</a></p>&mdash; EmbeddedLLM (@EmbeddedLLM) <a href="https://twitter.com/EmbeddedLLM/status/1942556855324270610?ref_src=twsrc%5Etfw">July 8, 2025</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

