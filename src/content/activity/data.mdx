---
title: Data
slug: data
description: "調べたり、集めたりしたデータです。"
---

調べたり、集めたりしたデータです。

## LLM KV Cache Sizing

updated: 2025-05-15


[この記事](/blog/2025/05/llm-kv-cache-size/)に従って、LLMのKV Cacheのサイズを試算しました。
あくまで机上の計算なので、実際のサイズとは異なる場合があります。


### google/gemma-3-12b-it

| 記号                           | 値               |
|--------------------------------|------------------|
| 2                              | 2                |
| B                              | 1 (とする)       |
| bytes/param                    | 2 (16 bit)       |
| n<sub>layers</sub>             | 48               |
| n<sub>kv_attention_heads</sub> | 8                |
| d<sub>attention_heads</sub>    | 3840 // 16 = 240 |
| context_length                 | 32k (とする)     |
| KV Cache サイズ                | 11GB             |

[google/gemma-3-12b-it (config.json)](https://huggingface.co/google/gemma-3-12b-it/blob/main/config.json)


### google/gemma-3-27b-it

| 記号                           | 値               |
|--------------------------------|------------------|
| 2                              | 2                |
| B                              | 1 (とする)       |
| bytes/param                    | 2 (16 bit)       |
| n<sub>layers</sub>             | 62               |
| n<sub>kv_attention_heads</sub> | 16               |
| d<sub>attention_heads</sub>    | 5376 // 32 = 168 |
| context_length                 | 32k (とする)     |
| KV Cache サイズ                | 19.9GB           |

[google/gemma-3-27b-it (config.json)](https://huggingface.co/google/gemma-3-27b-it/blob/main/config.json)


### Qwen/Qwen3-32B

| 記号                           | 値              |
|--------------------------------|-----------------|
| 2                              | 2               |
| B                              | 1 (とする)      |
| bytes/param                    | 2 (16 bit)      |
| n<sub>layers</sub>             | 64              |
| n<sub>kv_attention_heads</sub> | 8               |
| d<sub>attention_heads</sub>    | 5120 // 64 = 80 |
| context_length                 | 32k (とする)    |
| KV Cache サイズ                | 4.9GB           |

[Qwen/Qwen3-32B (config.json)](https://huggingface.co/Qwen/Qwen3-32B/blob/main/config.json)


### meta-llama/Llama-4-Scout-17B-16E-Instruct

| 記号                           | 値               |
|--------------------------------|------------------|
| 2                              | 2                |
| B                              | 1 (とする)       |
| bytes/param                    | 2 (16 bit)       |
| n<sub>layers</sub>             | 48               |
| n<sub>kv_attention_heads</sub> | 8                |
| d<sub>attention_heads</sub>    | 5120 // 40 = 128 |
| context_length                 | 32k (とする)     |
| KV Cache サイズ                | 5.9GB            |

[meta-llama/Llama-4-Scout-17B-16E-Instruct (config.json)](https://huggingface.co/meta-llama/Llama-4-Scout-17B-16E-Instruct/blob/main/config.json)
